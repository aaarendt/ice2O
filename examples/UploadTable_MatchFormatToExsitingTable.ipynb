{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload non-spatial table to the sandbox\n",
    "### Match format to existing table in  main portion of database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "sys.path.append(\"C:/Users/ehbaker/Documents/Python/Repos/ice2O\") #Path to where DBImport.py is saved\n",
    "import DbImport #User defined module in the folder added to path in line above.\n",
    "import numpy as np\n",
    "import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**User supplied criteria**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For draw wire\n",
    "db_table='draw_wire' #name of table in the database which you want to copy\n",
    "pth=(r\"Q:\\Project Data\\GlacierData\\WOLVERINE\\Draw_Wire\\data\\processed\\draw_wire_database.csv\") #path to csv for upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs=settings.import_cs() #user-defined module to store connection info\n",
    "engine = create_engine('postgresql://' + cs['user'] + ':' + str(cs['password']) + '@' + cs['host'] + ':' + cs['port'] + '/' + cs['dbname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in csv for upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in csv for upload\n",
    "df=pd.read_csv(pth) #read to dataframe\n",
    "#Extract format from existing table in main database\n",
    "types=DbImport.define_db_table_format(df, db_table, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names and Posgres data types for existing database table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attname</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>station_name</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extension</td>\n",
       "      <td>double precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datetime</td>\n",
       "      <td>timestamp without time zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gid</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        attname                         type\n",
       "0  station_name                         text\n",
       "1     extension             double precision\n",
       "2      datetime  timestamp without time zone\n",
       "3           gid                      integer"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for matching column names and order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to see if the columns in the new data frame match the ones in the database (order not important)\n",
    "columns_match=set(list(types['attname'])) ==set(list(df))\n",
    "columns_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reorder columns to match order of database table (important only for display)\n",
    "df=df[list(types['attname'])].copy() #the copy is neccesary to overwrite the initial dataframe with re-ordered values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set primary key in new table to match that in databse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary key for draw_wire is: gid\n",
      "Primary Key = Numeric \n",
      "Adding the primary key and unique IDs to rows of table being appended\n",
      "Primary key for draw_wire is: gid\n"
     ]
    }
   ],
   "source": [
    "#If numeric, add IDs sequentially, starting +1 from the current max\n",
    "res=DbImport.pkey_NameAndType(db_table, engine)\n",
    "pkey=res['attname'][0]\n",
    "pkey_type=res['data_type'][0]\n",
    "if pkey_type in ['smallint', 'integer', 'bigint', 'decimal', 'numeric', 'real', 'double precision', 'smallserial', 'serial', 'bigserial']:\n",
    "    print (\"Primary Key = Numeric \\nAdding the primary key and unique IDs to rows of table being appended\")\n",
    "    df=DbImport.add_sequential_IDs_to_pkey(df, db_table, engine) #overwrite table\n",
    "else:\n",
    "    print(\"Primary ID is not Numeric; must be updated manually\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>extension</th>\n",
       "      <th>datetime</th>\n",
       "      <th>gid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wolverine_siteEC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5/7/2016 16:05</td>\n",
       "      <td>68097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wolverine_siteEC</td>\n",
       "      <td>-0.010261</td>\n",
       "      <td>5/7/2016 17:05</td>\n",
       "      <td>68098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wolverine_siteEC</td>\n",
       "      <td>-0.020799</td>\n",
       "      <td>5/7/2016 18:05</td>\n",
       "      <td>68099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station_name  extension        datetime    gid\n",
       "0  Wolverine_siteEC   0.000000  5/7/2016 16:05  68097\n",
       "1  Wolverine_siteEC  -0.010261  5/7/2016 17:05  68098\n",
       "2  Wolverine_siteEC  -0.020799  5/7/2016 18:05  68099"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:3] #look at resulting table, with updated primary ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import table to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Connect to sandbox\n",
    "engine_sand = create_engine('postgresql://' + cs['user'] + ':' + str(cs['password']) + '@' + cs['host'] + ':' + cs['port'] + '/' + 'sandbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add subset of new table to sandbox\n",
    "df=df.sample(30) #overwrite table with a subset, as a test\n",
    "sandbox_tab_name=db_table +'_temp' #name for new table in sandbox portion of DB\n",
    "if columns_match==True:\n",
    "    df.to_sql(name=sandbox_tab_name, con=engine_sand, index = False, if_exists='replace')\n",
    "else: print(\"ERROR: columns in uploaded table do not match those in DB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change formatting specifics inside the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with station_name\n",
      "done with extension\n",
      "done with datetime\n",
      "done with gid\n",
      "DONE withdraw_wire_temp\n"
     ]
    }
   ],
   "source": [
    "#Reformat columns in sandbox to match format of those in existing table in spatial_database\n",
    "for xx in range(0,types.shape[0]):\n",
    "    col_name=types.attname[xx]\n",
    "    col_type=types.type[xx]\n",
    "    query=(r\"\"\"ALTER TABLE %s\n",
    "     ALTER COLUMN %s TYPE %s\n",
    "     USING %s::%s\"\"\")%(sandbox_tab_name, col_name, col_type, col_name, col_type)\n",
    "    engine_sand.execute(query)\n",
    "    print(\"done with \" +col_name)\n",
    "print(\"DONE with\" + sandbox_tab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x11957c88>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set primary key column\n",
    "engine_sand.execute(\"ALTER TABLE %s ADD PRIMARY KEY (%s);\"%(sandbox_tab_name, pkey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x116a3588>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set owner to Administrator\n",
    "engine_sand.execute(\"ALTER TABLE %s OWNER TO administrator\"%(sandbox_tab_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x11687908>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set permissions on tables. \n",
    "###These are currently not working, as passed thru SQLAlchemy engine; functional when passed direcly in SQL window in PgAdmin.\n",
    "engine_sand.execute(\"GRANT SELECT ON TABLE %s TO reader;\"%(sandbox_tab_name))\n",
    "engine_sand.execute(\"GRANT ALL ON TABLE %s TO administrator\"%(sandbox_tab_name))\n",
    "engine_sand.execute(\"ALTER TABLE %s OWNER TO administrator;\"%(sandbox_tab_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done! You have uploaded a table to the sandbox which matches structure of the original table (columns and types)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
