{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appending a Table to existing in Ice2O DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "sys.path.append(\"C:/Users/ehbaker/Documents/Python/Repos/ice2O\") #Path to where DBImport.py is saved\n",
    "import DbImport #This is a module that I have written, stored one directory up (cd ..)\n",
    "import numpy as np\n",
    "import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#User-supplied criteria:\n",
    "pth=(r\"Q:\\Project Data\\GlacierData\\WOLVERINE\\Draw_Wire\\data\\processed\\draw_wire_database.csv\") #path to csv for upload\n",
    "db_table='draw_wire' #name of table in the database which you want to copy\n",
    "sandbox_tab_name='draw_wire_ingest' #Name of table in database you want to append to. Data will match existing column types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Connect to the database\n",
    "cs=settings.import_cs()\n",
    "engine = create_engine('postgresql://' + cs['user'] + ':' + str(cs['password']) + '@' + cs['host'] + ':' + cs['port'] + '/' + cs['dbname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in table for upload\n",
    "df=pd.read_csv(r\"Q:\\Project Data\\GlacierData\\WOLVERINE\\Draw_Wire\\data\\processed\\draw_wire_database.csv\")\n",
    "#Specify the table in the database to which it will be appended.\n",
    "db_table='draw_wire'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Query database for column name of table primary key, and type (e.g. bigint, string, etc.)\n",
    "res=DbImport.pkey_NameAndType(db_table, engine)\n",
    "pkey=res['attname'][0]\n",
    "pkey_type=res['data_type'][0]\n",
    "if pkey_type in ['smallint', 'integer', 'bigint', 'decimal', 'numeric', 'real', 'double precision', 'smallserial', 'serial', 'bigserial']:\n",
    "   print (\"Primary Key = Numeric \\nAdding the primary key and unique IDs to rows of table being appended\")\n",
    "   df=DbImport.add_sequential_IDs_to_pkey(df, db_table, engine)\n",
    "else:\n",
    "   print(\"Primary ID is not Numeric; must be updated manually\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract format from existing table\n",
    "types=DbImport.define_db_table_format(db_table, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attname</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>station_name</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extension</td>\n",
       "      <td>double precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datetime</td>\n",
       "      <td>timestamp without time zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gid</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        attname                         type\n",
       "0  station_name                         text\n",
       "1     extension             double precision\n",
       "2      datetime  timestamp without time zone\n",
       "3           gid                      integer"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to see if the columns in the new data frame match the ones in the database (order not important)\n",
    "columns_match=set(list(types['attname'])) ==set(list(df))\n",
    "columns_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make dictionary with column name: type from the existing table in database\n",
    "dtype=dict(zip(types.attname, types.type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create connection to the sandbox\n",
    "engine_sand = create_engine('postgresql://' + cs['user'] + ':' + str(cs['password']) + '@' + cs['host'] + ':' + cs['port'] + '/' + 'sandbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add new table\n",
    "#APPENDING to existing table will automatically keep the column types intact!\n",
    "if columns_match==True:\n",
    "    df.to_sql(name=sandbox_tab_name, con=engine_sand, index = False, if_exists='append')\n",
    "else: print(\"ERROR: columns in uploaded table do not match those in DB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## And, we're done!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "May be possible to pass column types using 'dtype' in df.to_sql() using this answer:\n",
    "    http://stackoverflow.com/questions/34383000/pandas-to-sql-all-columns-as-nvarchar from Parfait\n",
    "    \n",
    "Spent a long time trying to make this work; it appears that not all types as encoded in postgresql are supported by SQLAlchemy; this makes passing them as a dictionary of colname: type very difficult.\n",
    "\n",
    "The functions written here are another promising avenue as well:\n",
    "https://www.ryanbaumann.com/blog/2016/4/30/python-pandas-tosql-only-insert-new-rows"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
