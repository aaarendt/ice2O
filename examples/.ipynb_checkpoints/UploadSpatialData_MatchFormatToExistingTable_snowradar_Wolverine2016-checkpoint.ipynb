{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Spatial Data to sandbox\n",
    "### Match format to existing table in  main portion of database\n",
    "Note: geometry information must be in columns labeled \"lat\" and \"long\"; geometry is created in column \"geom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "sys.path.append(\"C:/Users/ehbaker/Documents/Python/Repos/ice2O\") #Path to where DBImport.py is saved\n",
    "import DbImport #User defined module in the folder added to path in line above.\n",
    "import numpy as np\n",
    "import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User supplied criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For snow radar\n",
    "db_table='snowradar' #name of table in the database which you want to copy\n",
    "pth=(r\"Q:\\Project Data\\GlacierData\\GPR\\Wolverine\\2016\\Ice2ODatabase\\Wolverine_2016.csv\") #path to csv for upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to database and sandbox:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs=settings.import_cs() #user-defined module to store connection info\n",
    "#Spatial_database\n",
    "engine = create_engine('postgresql://' + cs['user'] + ':' + str(cs['password']) + '@' + cs['host'] + ':' + cs['port'] + '/' + cs['dbname'])\n",
    "#Sandbox\n",
    "engine_sand = create_engine('postgresql://' + cs['user'] + ':' + str(cs['password']) + '@' + cs['host'] + ':' + cs['port'] + '/' + 'sandbox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in csv for upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in csv for upload\n",
    "df=pd.read_csv(pth) #read to dataframe\n",
    "df=df.sample(30)\n",
    "#Extract format from existing table in main database\n",
    "types=DbImport.define_db_table_format(db_table, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names and Posgres data types for existing database table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     attname                  type\n",
      "0       elev      double precision\n",
      "1       twtt      double precision\n",
      "2  thickness      double precision\n",
      "3        swe      double precision\n",
      "4      trace               integer\n",
      "5       geom  geometry(Point,3338)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>elev</th>\n",
       "      <th>twtt</th>\n",
       "      <th>thickness</th>\n",
       "      <th>swe</th>\n",
       "      <th>collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>5728</td>\n",
       "      <td>-148.904429</td>\n",
       "      <td>60.385933</td>\n",
       "      <td>823.61</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.091</td>\n",
       "      <td>0.502</td>\n",
       "      <td>WOLVERINE_2016_D1_LINE02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345922</th>\n",
       "      <td>3112</td>\n",
       "      <td>-148.898922</td>\n",
       "      <td>60.426929</td>\n",
       "      <td>1401.60</td>\n",
       "      <td>112.9</td>\n",
       "      <td>12.193</td>\n",
       "      <td>5.609</td>\n",
       "      <td>WOLVERINE_2016_D3_LINE10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        trace        long        lat     elev   twtt  thickness    swe  \\\n",
       "3241     5728 -148.904429  60.385933   823.61   10.1      1.091  0.502   \n",
       "345922   3112 -148.898922  60.426929  1401.60  112.9     12.193  5.609   \n",
       "\n",
       "                      collection  \n",
       "3241    WOLVERINE_2016_D1_LINE02  \n",
       "345922  WOLVERINE_2016_D3_LINE10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the dataframe and the column types\n",
    "print(types) #data in DB\n",
    "df[0:2]#data in table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the order of columns in table to match that in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elev</th>\n",
       "      <th>twtt</th>\n",
       "      <th>thickness</th>\n",
       "      <th>swe</th>\n",
       "      <th>trace</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>823.61</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.091</td>\n",
       "      <td>0.502</td>\n",
       "      <td>5728</td>\n",
       "      <td>-148.904429</td>\n",
       "      <td>60.385933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345922</th>\n",
       "      <td>1401.60</td>\n",
       "      <td>112.9</td>\n",
       "      <td>12.193</td>\n",
       "      <td>5.609</td>\n",
       "      <td>3112</td>\n",
       "      <td>-148.898922</td>\n",
       "      <td>60.426929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           elev   twtt  thickness    swe  trace        long        lat\n",
       "3241     823.61   10.1      1.091  0.502   5728 -148.904429  60.385933\n",
       "345922  1401.60  112.9     12.193  5.609   3112 -148.898922  60.426929"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove columns in table that should be uploaded to the database (for snowradar, that is removing collection)\n",
    "cols_to_keep=list(set(list(df)) -(set(list(df)) -set(list(types['attname'])+ [u'long', u'lat'])))\n",
    "#Remove unwanted columns\n",
    "df=df[cols_to_keep]\n",
    "#Reorder columns to match order in DB, with the addition of lat/long, WITHOUT the geom column (will be created in SQL)\n",
    "df=df[list(types[~types.attname.str.contains(\"geom\")]['attname'])+[u'long', u'lat']].copy() #copy neccesary to overwrite\n",
    "df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for primary key, and if exists as numeric, add column for pkey in ingested table and continue numbering\n",
    "A better workflow may be to simply delete primary key and re-create with each upload. Currently the p-key as implemented in the database does not serve as a foreign key, and does not relate to any meaningful variable; rather, simple identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLEASE NOTE: Table has NO primary key\n",
      "No need to add primary key\n"
     ]
    }
   ],
   "source": [
    "#If numeric, add IDs sequentially, starting +1 from the current max\n",
    "res=DbImport.pkey_NameAndType(db_table, engine)\n",
    "if res=='None':\n",
    "    print(\"No need to add primary key\")\n",
    "else:\n",
    "    pkey=res['attname'][0]\n",
    "    pkey_type=res['data_type'][0]\n",
    "    if pkey_type in ['smallint', 'integer', 'bigint', 'decimal', 'numeric', 'real', 'double precision', 'smallserial', 'serial', 'bigserial']:\n",
    "        print (\"Primary Key = Numeric \\nAdding the primary key and unique IDs to rows of table being appended\")\n",
    "        df=DbImport.add_sequential_IDs_to_pkey(df, db_table, engine) #overwrite table\n",
    "    else:\n",
    "        print(\"Primary ID is not Numeric; must be updated manually\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snowradar_ingest'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the subset of data (df) to sandbox\n",
    "dbnamePts = db_table +'_ingest'\n",
    "df.to_sql(dbnamePts, engine_sand, index = False, if_exists='replace')\n",
    "dbnamePts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x12aa8780>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create geomoetry field:\n",
    "engine_sand.execute(\"\"\"ALTER TABLE %s ADD COLUMN geom geometry(Point, 3338);\"\"\" %(dbnamePts)) \n",
    "# populate the geometry field\n",
    "engine_sand.execute(\"\"\"UPDATE %s SET geom = ST_Transform(ST_setSRID(ST_MakePoint(long,lat),4326),3338);\"\"\" %(dbnamePts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attname</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elev</td>\n",
       "      <td>double precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twtt</td>\n",
       "      <td>double precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thickness</td>\n",
       "      <td>double precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>swe</td>\n",
       "      <td>double precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trace</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>geom</td>\n",
       "      <td>geometry(Point,3338)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     attname                  type\n",
       "0       elev      double precision\n",
       "1       twtt      double precision\n",
       "2  thickness      double precision\n",
       "3        swe      double precision\n",
       "4      trace               integer\n",
       "5       geom  geometry(Point,3338)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show format of model table\n",
    "types=DbImport.define_db_table_format(db_table, engine)\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with elev\n",
      "done with twtt\n",
      "done with thickness\n",
      "done with swe\n",
      "done with trace\n",
      "done with geom\n",
      "DONE with changing column types in snowradar_ingest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change columns of given name to given type; input is list format\n",
    "colnames=list(types.attname)\n",
    "coltypes=list(types.type)\n",
    "DbImport.set_column_types_to_match_other_table(colnames, coltypes, dbnamePts, engine=engine_sand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x12aa8400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove Lat and Long columns\n",
    "engine_sand.execute(\"ALTER TABLE %s DROP COLUMN IF EXISTS %s\"%(dbnamePts, 'lat'))\n",
    "engine_sand.execute(\"ALTER TABLE %s DROP COLUMN IF EXISTS %s\"%(dbnamePts, 'long'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x12a27828>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set owner to Administrator\n",
    "engine_sand.execute(\"ALTER TABLE %s OWNER TO administrator\"%(dbnamePts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRANT SELECT ON TABLE snowradar_ingest TO reader;\n",
      "GRANT ALL ON TABLE snowradar_ingest TO administrator;\n",
      "ALTER TABLE snowradar_ingest OWNER TO administrator;\n"
     ]
    }
   ],
   "source": [
    "#Queries that only work when passed DIRECTLY in SQL, and not thru Python SQLAlchemy\n",
    "query1=\"GRANT SELECT ON TABLE %s TO reader;\"%(dbnamePts)\n",
    "query2=\"GRANT ALL ON TABLE %s TO administrator;\"%(dbnamePts)\n",
    "query3=\"ALTER TABLE %s OWNER TO administrator;\"%(dbnamePts)\n",
    "print(query1)\n",
    "print(query2)\n",
    "print(query3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done! You have uploaded a table to the sandbox which matches structure of the original table (columns and types)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
