{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Spatial Data to sandbox\n",
    "### Match format to existing table in  main portion of database\n",
    "Note: geometry information must be in columns labeled \"lat\" and \"long\"; geometry is created in column \"geom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "sys.path.append(\"C:/Users/ehbaker/Documents/Python/Repos/ice2O\") #Path to where DBImport.py is saved\n",
    "import DbImport #User defined module in the folder added to path in line above.\n",
    "import numpy as np\n",
    "import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User supplied criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For snow radar\n",
    "db_table='snowradar' #name of table in the database which you want to copy\n",
    "pth=(r\"Q:\\Project Data\\GlacierData\\GPR\\Wolverine\\2016\\Ice2ODatabase\\Wolverine_2016.csv\") #path to csv for upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to database and sandbox:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs=settings.import_cs() #user-defined module to store connection info\n",
    "#Spatial_database\n",
    "engine = create_engine('postgresql://' + cs['user'] + ':' + str(cs['password']) + '@' + cs['host'] + ':' + cs['port'] + '/' + cs['dbname'])\n",
    "#Sandbox\n",
    "engine_sand = create_engine('postgresql://' + cs['user'] + ':' + str(cs['password']) + '@' + cs['host'] + ':' + cs['port'] + '/' + 'sandbox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in csv for upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in csv for upload\n",
    "df=pd.read_csv(pth) #read to dataframe\n",
    "df=df.sample(30)\n",
    "#Extract format from existing table in main database\n",
    "types=DbImport.define_db_table_format(df, db_table, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names and Posgres data types for existing database table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     attname                  type\n",
      "0       elev      double precision\n",
      "1       twtt      double precision\n",
      "2  thickness      double precision\n",
      "3        swe      double precision\n",
      "4      trace               integer\n",
      "5       geom  geometry(Point,3338)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>elev</th>\n",
       "      <th>twtt</th>\n",
       "      <th>thickness</th>\n",
       "      <th>swe</th>\n",
       "      <th>collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229555</th>\n",
       "      <td>7088</td>\n",
       "      <td>-148.914357</td>\n",
       "      <td>60.415756</td>\n",
       "      <td>1254.65</td>\n",
       "      <td>10.11</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.502</td>\n",
       "      <td>WOLVERINE_2016_D4_LINE08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75925</th>\n",
       "      <td>8991</td>\n",
       "      <td>-148.931324</td>\n",
       "      <td>60.425762</td>\n",
       "      <td>1357.35</td>\n",
       "      <td>82.00</td>\n",
       "      <td>8.856</td>\n",
       "      <td>4.074</td>\n",
       "      <td>WOLVERINE_2016_D1_LINE16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        trace        long        lat     elev   twtt  thickness    swe  \\\n",
       "229555   7088 -148.914357  60.415756  1254.65  10.11      1.092  0.502   \n",
       "75925    8991 -148.931324  60.425762  1357.35  82.00      8.856  4.074   \n",
       "\n",
       "                      collection  \n",
       "229555  WOLVERINE_2016_D4_LINE08  \n",
       "75925   WOLVERINE_2016_D1_LINE16  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the dataframe and the column types\n",
    "print(types) #data in DB\n",
    "df[0:2]#data in table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the order of columns in table to match that in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elev</th>\n",
       "      <th>twtt</th>\n",
       "      <th>thickness</th>\n",
       "      <th>swe</th>\n",
       "      <th>trace</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229555</th>\n",
       "      <td>1254.65</td>\n",
       "      <td>10.11</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.502</td>\n",
       "      <td>7088</td>\n",
       "      <td>-148.914357</td>\n",
       "      <td>60.415756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75925</th>\n",
       "      <td>1357.35</td>\n",
       "      <td>82.00</td>\n",
       "      <td>8.856</td>\n",
       "      <td>4.074</td>\n",
       "      <td>8991</td>\n",
       "      <td>-148.931324</td>\n",
       "      <td>60.425762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           elev   twtt  thickness    swe  trace        long        lat\n",
       "229555  1254.65  10.11      1.092  0.502   7088 -148.914357  60.415756\n",
       "75925   1357.35  82.00      8.856  4.074   8991 -148.931324  60.425762"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove columns in table that should be uploaded to the database (for snowradar, that is removing collection)\n",
    "cols_to_keep=list(set(list(df)) -(set(list(df)) -set(list(types['attname'])+ [u'long', u'lat'])))\n",
    "#Remove unwanted columns\n",
    "df=df[cols_to_keep]\n",
    "#Reorder columns to match order in DB, with the addition of lat/long, WITHOUT the geom column (will be created in SQL)\n",
    "df=df[list(types[~types.attname.str.contains(\"geom\")]['attname'])+[u'long', u'lat']].copy() #copy neccesary to overwrite\n",
    "df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for primary key, and if exists as numeric, add column for pkey in ingested table and continue numbering\n",
    "A better workflow may be to simply delete primary key and re-create with each upload. Currently the p-key as implemented in the database does not serve as a foreign key, and does not relate to any meaningful variable; rather, simple identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLEASE NOTE: Table has NO primary key\n",
      "No need to add primary key\n"
     ]
    }
   ],
   "source": [
    "#If numeric, add IDs sequentially, starting +1 from the current max\n",
    "res=DbImport.pkey_NameAndType(db_table, engine)\n",
    "if res=='None':\n",
    "    print(\"No need to add primary key\")\n",
    "else:\n",
    "    pkey=res['attname'][0]\n",
    "    pkey_type=res['data_type'][0]\n",
    "    if pkey_type in ['smallint', 'integer', 'bigint', 'decimal', 'numeric', 'real', 'double precision', 'smallserial', 'serial', 'bigserial']:\n",
    "        print (\"Primary Key = Numeric \\nAdding the primary key and unique IDs to rows of table being appended\")\n",
    "        df=DbImport.add_sequential_IDs_to_pkey(df, db_table, engine) #overwrite table\n",
    "    else:\n",
    "        print(\"Primary ID is not Numeric; must be updated manually\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add the subset of data (df) to sandbox\n",
    "dbnamePts = db_table +'_ingest'\n",
    "df.to_sql(dbnamePts, engine_sand, index = False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x36187b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create geomoetry field:\n",
    "engine_sand.execute(\"\"\"ALTER TABLE %s ADD COLUMN geom geometry(Point, 3338);\"\"\" %(dbnamePts)) \n",
    "# populate the geometry field\n",
    "engine_sand.execute(\"\"\"UPDATE %s SET geom = ST_Transform(ST_setSRID(ST_MakePoint(long,lat),4326),3338);\"\"\" %(dbnamePts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with elev\n",
      "done with twtt\n",
      "done with thickness\n",
      "done with swe\n",
      "done with trace\n",
      "done with geom\n",
      "DONE withsnowradar_ingest\n"
     ]
    }
   ],
   "source": [
    "#Reformat columns in sandbox to match format of those in existing table in spatial_database\n",
    "for xx in range(0,types.shape[0]):\n",
    "    col_name=types.attname[xx]\n",
    "    col_type=types.type[xx]\n",
    "    query=(r\"\"\"ALTER TABLE %s\n",
    "     ALTER COLUMN %s TYPE %s\n",
    "     USING %s::%s\"\"\")%(dbnamePts, col_name, col_type, col_name, col_type)\n",
    "    engine_sand.execute(query)\n",
    "    print(\"done with \" +col_name)\n",
    "print(\"DONE with\" + dbnamePts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x1285d080>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove Lat and Long columns\n",
    "engine_sand.execute(\"ALTER TABLE %s DROP COLUMN IF EXISTS %s\"%(dbnamePts, 'lat'))\n",
    "engine_sand.execute(\"ALTER TABLE %s DROP COLUMN IF EXISTS %s\"%(dbnamePts, 'long'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x999fef0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set owner to Administrator\n",
    "engine_sand.execute(\"ALTER TABLE %s OWNER TO administrator\"%(dbnamePts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x3618b38>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set permissions on tables. \n",
    "###These are currently not working, as passed thru SQLAlchemy engine; functional when passed direcly in SQL window in PgAdmin.\n",
    "engine_sand.execute(\"GRANT SELECT ON TABLE %s TO reader;\"%(dbnamePts))\n",
    "engine_sand.execute(\"GRANT ALL ON TABLE %s TO administrator\"%(dbnamePts))\n",
    "engine_sand.execute(\"ALTER TABLE %s OWNER TO administrator;\"%(dbnamePts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done! You have uploaded a table to the sandbox which matches structure of the original table (columns and types)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
